model_name,eval_loss,perplexity
42dot/42dot_LLM-SFT-1.3B,2.7736107897758484,tensor(16.0164)
google/gemma-1.1-2b-it,3.8986509457230567,tensor(49.3358)
